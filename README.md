# Data reconstruction from machine learning models via inverse estimation and Bayesian inference

**Authors:** 
[Agus Hartoyo](https://scholar.google.com/citations?user=ZCNIGmMAAAAJ&hl=pl&oi=ao), 
[Dominika Ciupek](https://scholar.google.com/citations?user=GiOOZ2IAAAAJ&hl=pl&oi=ao), 
[Maciej Malawski](https://scholar.google.com/citations?user=IeeOCucAAAAJ&hl=pl&oi=ao), and 
[Alessandro Crimi](https://scholar.google.com/citations?user=ciOVKiQAAAAJ&hl=pl&oi=ao)

## [Preprint](https://assets-eu.researchsquare.com/files/rs-5220310/v1_covered_9f00c1a4-fa1b-4cec-a826-054935182595.pdf?c=1731463344)

## Overview

<p align="justify"> This study explores the task of data reconstruction from machine learning models via inverse estimation and Bayesian inference, with the goal of recovering the original dataset solely based on the trained model. We introduce a novel theoretical framework that investigates the factors affecting the data reconstruction quality. Specifically, we derive expressions that quantify how variations in key variables influence the divergence between true and estimated posteriors by examining the concurrent behavior of their partial derivatives with respect to independent variables. This derivative-based approach establishes theoretical correlations between the variables, demonstrating that the fidelity of the recovered data is governed by two primary factors: (1) the accuracy of the assumed prior, and (2) the accuracy of the machine learning model. Empirical results across multiple benchmark datasets and machine learning algorithms corroborate these theoretical predictions, reinforcing the validity and robustness of our theoretical framework. Practically, our data reconstruction method enables the creation of synthetic models that closely replicate the performance of the original models. This work contributes to advancing the theoretical understanding and practical techniques for data reconstruction and model introspection within the context of machine learning. </p>
